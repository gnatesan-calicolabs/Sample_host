:py:mod:`layers`
================

.. py:module:: layers


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   layers.Clip
   layers.Exp
   layers.Scale
   layers.PolyReLU
   layers.Softplus
   layers.CenterSlice
   layers.CenterAverage
   layers.LengthAverage
   layers.MultiheadAttention
   layers.WheezeExcite
   layers.SqueezeExcite
   layers.GlobalContext
   layers.SoftmaxPool1D
   layers.ConcatPosition
   layers.OneToTwo
   layers.AverageTo2D
   layers.MaxTo2D
   layers.DotTo2D
   layers.GeoDotTo2D
   layers.ConcatTo2D
   layers.ConcatDist2D
   layers.UpperTri
   layers.Symmetrize2D
   layers.EnsembleReverseComplement
   layers.StochasticReverseComplement
   layers.SwitchReverse
   layers.SwitchReverseTriu
   layers.EnsembleShift
   layers.StochasticShift
   layers.FactorInverse



Functions
~~~~~~~~~

.. autoapisummary::

   layers.rope
   layers._prepend_dims
   layers.positional_features_central_mask
   layers.gamma_pdf
   layers.positional_features_gamma
   layers.get_positional_feature_function
   layers.positional_features_all
   layers.positional_features
   layers.relative_shift
   layers.shift_sequence
   layers.activate



.. py:class:: Clip(min_value, max_value)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: Exp(base=None, minus=None)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: Scale(axis=-1, initializer='zeros')

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: build(input_shape)


   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: PolyReLU(shift=0)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)



.. py:class:: Softplus(exp_max=10000)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: CenterSlice(center)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: CenterAverage(center)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: LengthAverage

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x, seq)



.. py:function:: rope(x, axis)

   RoPE position embedding.
   From Hua et al. Transformer Quality in Linear Time.


.. py:function:: _prepend_dims(x, num_dims)


.. py:function:: positional_features_central_mask(positions: tensorflow.Tensor, feature_size: int, seq_length: int)

   Positional features using a central mask (allow only central features).


.. py:function:: gamma_pdf(x, concentration, rate)

   Gamma probability distribution function: p(x|concentration, rate).


.. py:function:: positional_features_gamma(positions: tensorflow.Tensor, feature_size: int, seq_length: Optional[int] = None, bin_size: Optional[int] = None, stddev=None, start_mean=None)

   Positional features computed using the gamma distributions.


.. py:function:: get_positional_feature_function(name)

   Returns positional feature functions.


.. py:function:: positional_features_all(positions: tensorflow.Tensor, feature_size: int, seq_length: Optional[int] = None, bin_size: Optional[int] = None, feature_functions: Optional[List[str]] = None, symmetric=False)

   Compute relative positional encodings/features.

   Each positional feature function will compute/provide the same fraction of
   features, making up the total of feature_size.

   Args:
     positions: Tensor of relative positions of arbitrary shape.
     feature_size: Total number of basis functions.
     seq_length: Sequence length denoting the characteristic length that
       the individual positional features can use. This is required since the
       parametrization of the input features should be independent of `positions`
       while it could still require to use the total number of features.
     bin_size: Bin sized used to partition the sequence. This can be used to
       compute features on the absolute scale relative to the genome.
     feature_functions: List of different feature functions to use. Each function
       will take as argument: positions, sequence length and number of features
       to compute.
     symmetric: If True, the resulting features will be symmetric across the
       relative position of 0 (i.e. only absolute value of positions will
       matter). If false, then both the symmetric and asymmetric version
       (symmetric multiplied by sign(positions)) of the features will be used.

   Returns:
     Tensor of shape: `positions.shape + (feature_size,)`.


.. py:function:: positional_features(positions: tensorflow.Tensor, feature_size: int, seq_length: int, symmetric=False)

   Compute relative positional encodings/features.

   Each positional feature function will compute/provide the same fraction of
   features, making up the total of feature_size.

   Args:
     positions: Tensor of relative positions of arbitrary shape.
     feature_size: Total number of basis functions.
     seq_length: Sequence length denoting the characteristic length that
       the individual positional features can use. This is required since the
       parametrization of the input features should be independent of `positions`
       while it could still require to use the total number of features.
     symmetric: If True, the resulting features will be symmetric across the
       relative position of 0 (i.e. only absolute value of positions will
       matter). If false, then both the symmetric and asymmetric version
       (symmetric multiplied by sign(positions)) of the features will be used.

   Returns:
     Tensor of shape: `positions.shape + (feature_size,)`.


.. py:function:: relative_shift(x)

   Shift the relative logits like in TransformerXL.


.. py:class:: MultiheadAttention(value_size, key_size, heads, scaling=True, attention_dropout_rate=0, relative_position_symmetric=False, relative_position_functions=['positional_features_central_mask'], num_position_features=None, positional_dropout_rate=0, content_position_bias=True, zero_initialize=True, transpose_stride=0, gated=False, initializer='he_normal', l2_scale=0, qkv_width=1)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Multi-head attention.

   .. py:method:: _multihead_output(linear_layer, inputs)

      Applies a standard linear to inputs and returns multihead output.


   .. py:method:: call(inputs, training=False)


   .. py:method:: get_config()



.. py:class:: WheezeExcite(pool_size)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: build(input_shape)


   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: SqueezeExcite(activation='relu', additive=False, bottleneck_ratio=8, norm_type=None, bn_momentum=0.9)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: build(input_shape)


   .. py:method:: call(x)


   .. py:method:: get_config()



.. py:class:: GlobalContext

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: build(input_shape)


   .. py:method:: call(x)



.. py:class:: SoftmaxPool1D(pool_size: int = 2, per_channel: bool = False, init_gain: float = 2.0)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Pooling operation with optional weights.

   .. py:method:: build(input_shape)


   .. py:method:: call(inputs)


   .. py:method:: get_config()



.. py:class:: ConcatPosition(transform=None, power=1)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Concatenate position to 1d feature vectors.

   .. py:method:: call(inputs)


   .. py:method:: get_config()



.. py:class:: OneToTwo(operation='mean')

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors operated on.

   .. py:method:: call(oned)


   .. py:method:: get_config()



.. py:class:: AverageTo2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors averaged.

   .. py:method:: call(inputs)



.. py:class:: MaxTo2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors maxed.

   .. py:method:: call(inputs)



.. py:class:: DotTo2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors maxed.

   .. py:method:: call(inputs)



.. py:class:: GeoDotTo2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors maxed.

   .. py:method:: call(inputs)



.. py:class:: ConcatTo2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Transform 1d to 2d with i,j vectors concatenated.

   .. py:method:: call(inputs)



.. py:class:: ConcatDist2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Concatenate the pairwise distance to 2d feature matrix.

   .. py:method:: call(inputs)



.. py:class:: UpperTri(diagonal_offset=2)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Unroll matrix to its upper triangular portion.

   .. py:method:: call(inputs)


   .. py:method:: get_config()



.. py:class:: Symmetrize2D

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Take the average of a matrix and its transpose to enforce symmetry.

   .. py:method:: call(x)



.. py:class:: EnsembleReverseComplement

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Expand tensor to include reverse complement of one hot encoded DNA sequence.

   .. py:method:: call(seqs_1hot)



.. py:class:: StochasticReverseComplement

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Stochastically reverse complement a one hot encoded DNA sequence.

   .. py:method:: call(seq_1hot, training=None)



.. py:class:: SwitchReverse(strand_pair=None)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Reverse predictions if the inputs were reverse complemented.

   .. py:method:: call(x_reverse)


   .. py:method:: get_config()



.. py:class:: SwitchReverseTriu(diagonal_offset)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   .. py:method:: call(x_reverse)


   .. py:method:: get_config()



.. py:class:: EnsembleShift(shifts=[0], pad='uniform')

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Expand tensor to include shifts of one hot encoded DNA sequence.

   .. py:method:: call(seqs_1hot)


   .. py:method:: get_config()



.. py:class:: StochasticShift(shift_max=0, symmetric=True, pad='uniform')

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Stochastically shift a one hot encoded DNA sequence.

   .. py:method:: call(seq_1hot, training=None)


   .. py:method:: get_config()



.. py:function:: shift_sequence(seq, shift, pad_value=0)

   Shift a sequence left or right by shift_amount.

   Args:
   seq: [batch_size, seq_length, seq_depth] sequence
   shift: signed shift value (tf.int32 or int)
   pad_value: value to fill the padding (primitive or scalar tf.Tensor)


.. py:class:: FactorInverse(components_npy)

   Bases: :py:obj:`tensorflow.keras.layers.Layer`

   Inverse a target matrix factorization.

   .. py:method:: call(W)


   .. py:method:: get_config()



.. py:function:: activate(current, activation, verbose=False)


