:py:mod:`bam_cov`
=================

.. py:module:: bam_cov


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   bam_cov.GenomeCoverage



Functions
~~~~~~~~~

.. autoapisummary::

   bam_cov.main
   bam_cov.compute_cut_norms
   bam_cov.row_nzcols_geti
   bam_cov.row_nzcols_get
   bam_cov.row_nzcols_set
   bam_cov.single_or_pair
   bam_cov.distribute_multi_succint
   bam_cov.initialize_kmers
   bam_cov.regplot_gc
   bam_cov.regplot_shift
   bam_cov.cigar_len
   bam_cov.scatter_lims



.. py:function:: main()


.. py:function:: compute_cut_norms(cut_bias_kmer, read_weights, chromosomes, chrom_lengths, fasta_file)

   Compute cut bias normalizations.

       UNFINISHED!

   Args:
    cut_bias_kmer
    read_weights
    chromosomes
    chrom_lengths
    fasta_file

    Returns:
     kmer_norms


.. py:function:: row_nzcols_geti(m, ri)

   Return row ri's nonzero columns. 


.. py:function:: row_nzcols_get(m, ri)

   Return row ri's nonzero columns. 


.. py:function:: row_nzcols_set(m, ri, v)

   Set row ri's nonzero columsn to v. 


.. py:function:: single_or_pair(bam_file)

   Check the first read to guess if the BAM has single or paired end reads.


.. py:function:: distribute_multi_succint(multi_weight_matrix, genome_unique_coverage, multi_window, chrom_lengths, max_iterations=10, converge_t=0.01)

   Wondering if I can speed things up by vectorizing these operations, but still much to test.

   1. start by comparing the times to make my genome_coverage estimate here with multi_weight_matrix.sum(axis=0) versus looping through the arrays myself.
   2. then benchmark that dot product.
   3. then benchmark the column normalization.
   4. then determine a way to assess convergence. maybe sample 1k reads to act as my proxy?



.. py:function:: initialize_kmers(k, pseudocount=1.0)

   Initialize a dict mapping kmers to cut counts.

   Args
    k (int): k-mer size
    pseudocount (float): Initial pseudocount



.. py:function:: regplot_gc(vals1, vals2, model, out_pdf)


.. py:function:: regplot_shift(vals1, vals2, preds2, out_pdf)


.. py:class:: GenomeCoverage(chrom_lengths, stranded=False, smooth_multi_sd=1, clip_max=None, clip_max_multi=None, shift_center=False, shift_forward=0, shift_reverse=0, all_overlap=False, all_unique=False, maps_t=1, fasta_file=None)

   chrom_lengths (OrderedDict): Mapping chromosome names to lengths.
   fasta (pysam Fastafile):

   unique_counts: G (genomic position) array of unique coverage counts.
   multi_weight_matrix: R (reads) x G (genomic position) array of
   multi-mapping read weight.
   smooth_multi_sd (int): Multi-map distribution gaussian filter standard deviation.
   multi_max (int): Maximum coverage per position from multi-mappers due to
   mis-mapping fear.
   shift (int): Alignment shift to maximize cross-strand coverage correlation

   .. py:method:: align_shifts(align)

      Helper function to determine alignment event position shifts. 


   .. py:method:: distribute_multi(max_iterations=4, converge_t=0.05)

      Distribute multi-mapping read weight proportional to coverage in a local window.

      In
       max_iterations: Maximum iterations through the reads.
       converge_t: Per read weight difference below which we consider
       convergence.



   .. py:method:: estimate_coverage(genome_coverage, pseudocount=0.01)

      Estimate smoothed genomic coverage.

      In
       genome_coverage: G (genomic position) array of estimated coverage
       counts.
       pseudocount (int): Coverage pseudocount.


   .. py:method:: gc_normalize(chrom, coverage)

      Apply a model to normalize for GC content.

      In
       chrom (str): Chromosome
       coverage ([float]): Coverage array
       pseudocount (int): Coverage pseudocount.

      Out
       model (sklearn object): To control for GC%.


   .. py:method:: learn_gc(fragment_sd=64, pseudocount=0.01, out_dir=None)

      Learn a model to normalize for GC content.

      In
       fragment_sd (int): Gaussian filter standard deviation.
       pseudocount (int): Coverage pseudocount.

      Out
       model (sklearn object): To control for GC%.


   .. py:method:: learn_gc_base()

      Determine the genome-wide GC model baseline

      In
       self.gc_model

      Out
       self.gc_base


   .. py:method:: index_genome(gi)

      Compute chromosome and position for a genome index.

      Args
       gi (int): Genomic index

      Returns:
       ci (int): Chromosome index.
       pos (int): Position.


   .. py:method:: genome_index(ci, pos, strand=None)

      Compute genome index for a chromosome index and position.

      Args
       ci (int): Chromosome index.
       pos (int): Position.
       strand (str): '+' or '-'

      Returns:
       gi (int): Genomic index


   .. py:method:: genome_indexes(ci, positions, strand=None)

      Compute genome indexes for a chromosome index and positions.

      Args
       ci (int): Chromosome index.
       positions (int): Position(s)
       strand (str): '+' or '-'

      Returns:
       gi (int): Genomic index


   .. py:method:: genome_index_chrom(chrom, pos, strand=None)

      Compute genome index for a chromosome label and position.

      Args
       chrom (str): Chromosome label.
       pos (int): Position.
       strand (str): '+' or '-'

      Returns:
       gi (int): Genomic index


   .. py:method:: genome_chr(genome_indexes, chrom)

      Filter and convert an array of genome indexes
          to indexes for a specific chromosome.

      Args
       genome_indexes (np.array):
       chrom (str):

      Returns
       chrom_indexes (np.array)


   .. py:method:: learn_shift_pair(bam_file)

      Learn the optimal fragment shift from paired end fragments. 


   .. py:method:: learn_shift_single(bam_file, shift_min=50, shift_max=350, out_dir=None)

      Learn the optimal fragment shift that maximizes across strand correlation

      (to be applied for single end discordant alignments.)


   .. py:method:: read_bam(bam_file, genome_sorted=False, all_overlap=False)

      Read alignments from a BAM file into unique and multi data structures.


   .. py:method:: infer_active_blocks(genome_coverage, min_inactive=50000)


   .. py:method:: infer_active_blocks_groupby(genome_coverage, min_inactive=50000)

      Infer active genomic blocks that we'll need to consider.

      The non-groupby version is inefficient. This one should improve it,
       but it's unfinished.


   .. py:method:: read_multi_bwa(multi_positions, multi_reads, multi_weight, align, gi, ri, align_shift_forward, align_shift_reverse)

      Helper function to process a BWA multi-mapper. 


   .. py:method:: read_multi_nh(multi_positions, multi_reads, multi_weight, align, gis, ri, read_id, last_read_id, genome_sorted, multi_read_index)

      Helper function to process an NH-tagged multi-mapper. 


   .. py:method:: set_clips(coverage)

      Hash indexes to clip at various thresholds.

      Must run this before running clip_multi, which will use
      self.multi_clip_indexes. The objective is to estimate
      coverage conservatively w/ clip_max and smoothing before
      asking whether the raw coverage count is compelling.

      In:
       coverage (np.array): Pre-clipped genome coverage.

      Out:
        self.adaptive_t (int->float): Clip values mapped to coverage thresholds
                                      above which to apply them.
        self.multi_clip_indexes (int->np.array): Clip values mapped to genomic
                                                 indexes to clip.


   .. py:method:: clip_multi(coverage, chrom=None)

      Clip coverage at adaptively-determined thresholds.

      Must run set_clips to set self.multi_clip_indexes. If self.adaptive_t
      is empty, I know it hasn't been run yet.

      In:
       coverage (np.array): Pre-clipped genome/chromosome coverage.
       chrom (str): Single chromosome coverage.

      Out:
       coverage (np.array): Clipped coverage values


   .. py:method:: write(output_file, single_or_pair, smooth_sd=0, zero_eps=0.003)

      Compute and write out coverage to bigwig file.

      Go chromosome by chromosome here to facilitate printing,
      and save memory.

      In:
       output_file (str): HDF5 or BigWig filename.
       single_or_pair (bool): Specifies whether to correct for paired end double coverage.



.. py:function:: cigar_len(cigar_str)


.. py:function:: scatter_lims(vals1, vals2=None, buffer=0.05)


